# v4: 스킬 메커니즘

**핵심 인사이트: 스킬은 도구가 아니라 지식 패키지입니다.**

## 지식 외부화: 학습에서 편집으로

스킬은 심오한 패러다임 전환을 구현합니다: **지식 외부화**.

### 전통적 접근 방식: 파라미터에 내재화된 지식

전통적인 AI 시스템은 모든 지식을 모델 파라미터에 저장합니다. 접근하거나, 수정하거나, 재사용할 수 없습니다.

모델이 새로운 스킬을 배우길 원하나요? 다음이 필요합니다:
1. 대규모 학습 데이터 수집
2. 분산 학습 클러스터 설정
3. 복잡한 파라미터 파인튜닝 수행 (LoRA, 전체 파인튜닝 등)
4. 새 모델 버전 배포

뇌가 갑자기 기억을 잃었는데 복구할 노트가 없는 것과 같습니다. 지식은 신경망의 가중치 행렬에 잠겨 있어 사용자에게 완전히 불투명합니다.

### 새로운 패러다임: 문서로 외부화된 지식

코드 실행 패러다임이 모든 것을 바꿉니다.

```
┌──────────────────────────────────────────────────────────────────────┐
│                       지식 저장 계층                                   │
│                                                                       │
│  모델 파라미터 → 컨텍스트 윈도우 → 파일 시스템 → 스킬 라이브러리          │
│    (내재화)         (런타임)       (영구)        (구조화)                │
│                                                                       │
│  ←────── 학습 필요 ──────→  ←─── 자연어 편집 ────→                     │
│    클러스터, 데이터, 전문성 필요        누구나 수정 가능                   │
└──────────────────────────────────────────────────────────────────────┘
```

**핵심 돌파구**:
- **이전**: 모델 행동 수정 = 파라미터 수정 = 학습 필요 = GPU 클러스터 + 학습 데이터 + ML 전문성
- **지금**: 모델 행동 수정 = SKILL.md 편집 = 텍스트 파일 편집 = 누구나 가능

기본 모델에 핫스왑 가능한 LoRA 어댑터를 부착하는 것과 같지만, 파라미터 학습 없이.

### 왜 이것이 중요한가

1. **민주화**: 모델 행동 커스터마이징에 ML 전문성 불필요
2. **투명성**: 지식이 사람이 읽을 수 있는 마크다운에 저장, 감사 및 이해 가능
3. **재사용성**: 스킬을 한 번 작성하면 호환 가능한 모든 에이전트에서 사용
4. **버전 관리**: Git이 지식 변경 관리, 협업과 롤백 지원
5. **온라인 학습**: 모델이 더 큰 컨텍스트 윈도우에서 "학습", 오프라인 학습 불필요

전통적인 파인튜닝은 **오프라인 학습**입니다: 데이터 수집 -> 학습 -> 배포 -> 사용.
스킬은 **온라인 학습**을 가능하게 합니다: 런타임에 필요에 따라 지식 로드, 즉시 효과.

### 지식 계층 비교

| 계층 | 수정 | 적용 시간 | 영속성 | 비용 |
|------|------|----------|--------|------|
| 모델 파라미터 | 학습/파인튜닝 | 시간~일 | 영구 | $10K-$1M+ |
| 컨텍스트 윈도우 | API 호출 | 즉시 | 세션당 | ~$0.01/호출 |
| 파일 시스템 | 파일 편집 | 다음 로드 | 영구 | 무료 |
| **스킬 라이브러리** | **SKILL.md 편집** | **다음 트리거** | **영구** | **무료** |

스킬은 스위트 스팟을 차지합니다: 영구 저장 + 필요시 로드 + 사람이 편집 가능.

### 실제 예시

Claude가 회사의 특정 코딩 표준을 배우길 원한다고 가정합시다:

**전통적 방식**:
```
1. 회사 코드베이스를 학습 데이터로 수집
2. 파인튜닝 스크립트와 인프라 준비
3. LoRA 파인튜닝 실행 (GPU 필요)
4. 커스텀 모델 배포
5. 비용: $1000+ 및 수 주의 시간
```

**스킬 방식**:
```markdown
# skills/company-standards/SKILL.md
---
name: company-standards
description: 회사 코딩 표준과 모범 사례
---

## 네이밍 컨벤션
- 함수는 lowercase_with_underscores 사용
- 클래스는 PascalCase 사용
...
```
```
비용: $0, 시간: 5분
```

이것이 지식 외부화의 힘입니다: **학습이 필요했던 지식을 누구나 편집할 수 있는 문서로 전환**.

## 문제점

v3은 작업 분해를 위한 서브에이전트를 제공했습니다. 하지만 더 깊은 질문이 있습니다: **모델은 도메인 특화 작업을 어떻게 처리해야 하는지 어떻게 아나요?**

- PDF 처리? `pdftotext` vs `PyMuPDF`를 알아야 합니다
- MCP 서버 구축? 프로토콜 스펙과 모범 사례를 알아야 합니다
- 코드 리뷰? 체계적인 체크리스트가 필요합니다

이 지식은 도구가 아닙니다—**전문성**입니다. 스킬은 모델이 필요에 따라 도메인 지식을 로드할 수 있게 함으로써 이를 해결합니다.

## 핵심 개념

### 1. 도구 vs 스킬

| 개념 | 무엇인가 | 예시 |
|------|---------|------|
| **도구** | 모델이 할 수 있는 것 | bash, read_file, write_file |
| **스킬** | 모델이 어떻게 하는지 아는 것 | PDF 처리, MCP 구축 |

도구는 능력입니다. 스킬은 지식입니다.

### 2. 점진적 공개

```
Layer 1: 메타데이터 (항상 로드됨)      ~100 토큰/스킬
         └─ name + description

Layer 2: SKILL.md 본문 (트리거 시)     ~2000 토큰
         └─ 상세 지시사항

Layer 3: 리소스 (필요시)               무제한
         └─ scripts/, references/, assets/
```

이것은 컨텍스트를 가볍게 유지하면서 임의의 깊이의 지식을 허용합니다.

### 3. SKILL.md 표준

```
skills/
├── pdf/
│   └── SKILL.md          # 필수
├── mcp-builder/
│   ├── SKILL.md
│   └── references/       # 선택
└── code-review/
    ├── SKILL.md
    └── scripts/          # 선택
```

**SKILL.md 형식**: YAML frontmatter + Markdown 본문

```markdown
---
name: pdf
description: PDF 파일 처리. PDF를 읽거나, 생성하거나, 병합할 때 사용.
---

# PDF 처리 스킬

## PDF 읽기

빠른 추출을 위해 pdftotext 사용:
\`\`\`bash
pdftotext input.pdf -
\`\`\`
...
```

## 구현 (~100줄 추가)

### SkillLoader 클래스

```python
class SkillLoader:
    def __init__(self, skills_dir: Path):
        self.skills = {}
        self.load_skills()

    def parse_skill_md(self, path: Path) -> dict:
        """YAML frontmatter + Markdown 본문 파싱."""
        content = path.read_text()
        match = re.match(r'^---\s*\n(.*?)\n---\s*\n(.*)$', content, re.DOTALL)
        # {name, description, body, path, dir} 반환

    def get_descriptions(self) -> str:
        """시스템 프롬프트용 메타데이터 생성."""
        return "\n".join(f"- {name}: {skill['description']}"
                        for name, skill in self.skills.items())

    def get_skill_content(self, name: str) -> str:
        """컨텍스트 주입을 위한 전체 내용 가져오기."""
        return f"# Skill: {name}\n\n{skill['body']}"
```

### Skill 도구

```python
SKILL_TOOL = {
    "name": "Skill",
    "description": "전문화된 지식을 얻기 위해 스킬 로드.",
    "input_schema": {
        "properties": {"skill": {"type": "string"}},
        "required": ["skill"]
    }
}
```

### 메시지 주입 (캐시 보존)

핵심 인사이트: 스킬 콘텐츠는 시스템 프롬프트가 아니라 **tool_result** (사용자 메시지의 일부)로 들어갑니다:

```python
def run_skill(skill_name: str) -> str:
    content = SKILLS.get_skill_content(skill_name)
    # 전체 내용이 tool_result로 반환됨
    # 대화 히스토리의 일부가 됨 (사용자 메시지)
    return f"""<skill-loaded name="{skill_name}">
{content}
</skill-loaded>

위 스킬의 지시를 따르세요."""

def agent_loop(messages: list) -> list:
    while True:
        response = client.messages.create(
            model=MODEL,
            system=SYSTEM,  # 절대 변하지 않음 - 캐시 보존!
            messages=messages,
            tools=ALL_TOOLS,
        )
        # 스킬 콘텐츠가 tool_result로 messages에 들어감...
```

**핵심 인사이트**:
- 스킬 콘텐츠는 새 메시지로 **끝에 추가됨**
- 이전의 모든 것 (시스템 프롬프트 + 이전 모든 메시지)는 캐시되어 재사용됨
- 새로 추가된 스킬 콘텐츠만 계산 필요 — **전체 접두사가 캐시 히트**

## 프로덕션과 비교

| 메커니즘 | Claude Code / Kode | v4 |
|----------|-------------------|-----|
| 형식 | SKILL.md (YAML + MD) | 동일 |
| 로딩 | Container API | SkillLoader 클래스 |
| 트리거 | 자동 + Skill 도구 | Skill 도구만 |
| 주입 | newMessages (사용자 메시지) | tool_result (사용자 메시지) |
| 캐싱 | 끝에 추가, 전체 접두사 캐시됨 | 끝에 추가, 전체 접두사 캐시됨 |
| 버저닝 | Skill Versions API | 생략 |
| 권한 | allowed-tools 필드 | 생략 |

**핵심 유사점**: 둘 다 스킬 콘텐츠를 대화 히스토리에 주입 (시스템 프롬프트가 아님), 프롬프트 캐시 보존.

## 왜 이것이 중요한가: 캐싱 경제학

### 캐시 무시의 비용

**LangGraph, LangChain, AutoGen**을 사용하는 많은 개발자들이 습관적으로:
- 동적 상태를 시스템 프롬프트에 주입
- 메시지 히스토리 편집 및 압축
- 슬라이딩 윈도우로 대화 잘라내기

**이러한 작업은 캐시를 무효화하고 비용을 7-50배 폭증시킵니다.**

일반적인 50라운드 SWE 작업:
- **캐시 파괴**: $14.06 (매 라운드 시스템 프롬프트 수정)
- **캐시 최적화**: $1.85 (추가만)
- **절감**: 86.9%

하루 100개 작업을 처리하는 앱의 경우, **연간 $45,000+ 절감**을 의미합니다.

### 자기회귀 모델과 KV 캐시

LLM은 자기회귀적입니다: 각 토큰을 생성하려면 이전의 모든 토큰에 어텐션을 해야 합니다. 중복 계산을 피하기 위해 제공업체는 **KV Cache**를 구현합니다:

```
요청 1: [System, User1, Asst1, User2]
        ←────── 전부 계산 ──────→

요청 2: [System, User1, Asst1, User2, Asst2, User3]
        ←────── 캐시 히트 ──────→ ←─ 신규 ─→
                (0.1x 가격)         (일반 가격)
```

캐시 히트는 **정확한 접두사 일치**가 필요합니다. 시스템 프롬프트나 히스토리를 수정하면 전체 접두사 캐시가 무효화됩니다.

### 일반적인 안티패턴

| 안티패턴 | 효과 | 비용 배수 |
|----------|------|----------|
| 동적 시스템 프롬프트 | 100% 캐시 미스 | **20-50x** |
| 메시지 압축 | 교체 지점부터 무효화 | **5-15x** |
| 슬라이딩 윈도우 | 100% 캐시 미스 | **30-50x** |
| 메시지 편집 | 편집 지점부터 무효화 | **10-30x** |
| 멀티 에이전트 풀 메시 | 컨텍스트 폭발 | **3-4x** (단일 에이전트 대비) |

### 제공업체 차이

| 제공업체 | 자동 캐시 | 할인 | 설정 |
|----------|----------|------|------|
| Claude | X | 90% | `cache_control` 필요 |
| GPT-5.2 | O | 90% | 설정 불필요 |
| Kimi K2 | O | 90% | 설정 불필요 |
| GLM-4.7 | O | 82% | 설정 불필요 |
| MiniMax M2.1 | X | 90% | `cache_control` 필요 |
| Gemini 3 | O (암시적) | 90% | 설정 불필요 |

**중요**: Claude와 MiniMax는 명시적 `cache_control` 설정이 필요합니다—그렇지 않으면 캐시 히트가 없습니다.

### 권장: 추가만

```python
# 잘못됨: 히스토리 편집
messages[2]["content"] = "edited"  # 캐시 무효화!

# 옳음: 추가만
messages.append(new_msg)  # 접두사 불변, 캐시 히트

# 잘못됨: 동적 시스템 프롬프트
system = f"State: {state}"  # 매번 변함!

# 옳음: 고정 시스템, 상태는 메시지에
SYSTEM = "You are an assistant."  # 절대 변하지 않음
messages.append({"role": "user", "content": f"State: {state}"})
```

### 컨텍스트 길이 지원

현대 모델은 큰 컨텍스트 윈도우를 지원합니다:
- Claude Sonnet 4.5 / Opus 4.5: **200K**
- GPT-5.2: **256K+**
- Gemini 3 Flash/Pro: **1M-2M**

200K 토큰 ≈ 15만 단어 ≈ 500페이지 책. 대부분의 Agent 작업에서 기존 컨텍스트 윈도우로 충분합니다.

> **컨텍스트를 편집 가능한 문서가 아니라 추가 전용 로그로 취급하세요.**

### 딥 다이브

캐싱 경제학에 대한 포괄적인 내용:
1. **일반적인 안티패턴**: LangGraph/LangChain의 5가지 캐시 파괴 실수
2. **상세 계산**: 50라운드 SWE 작업의 라운드별 비용 분석
3. **제공업체 전략**: 제공업체별 캐시 메커니즘 및 가격 비교
4. **에이전트 오케스트레이션**: 토큰 소비 차이 (멀티 에이전트 ~3-4x vs 단일 에이전트)
5. **모범 사례**: 캐시 파괴 문제 감지 및 수정 방법

참조: [컨텍스트 캐싱 경제학: Agent 개발자를 위한 비용 최적화 가이드](../articles/上下文缓存经济学.md) (중국어)

## 철학: 실제에서의 지식 외부화

> **지식을 일급 시민으로**

처음에 논의한 지식 외부화 패러다임으로 돌아갑니다. 전통적 관점: AI 에이전트는 "도구 호출자"입니다—모델이 어떤 도구를 결정하고, 코드가 실행합니다.

하지만 이것은 핵심 차원을 놓칩니다: **모델은 무엇을 해야 하는지 어떻게 아나요?**

스킬은 지식 외부화의 완전한 실천입니다:

**이전 (지식 내재화)**:
- 지식이 모델 파라미터에 잠김
- 수정에 학습 필요 (LoRA, 전체 파인튜닝)
- 사용자가 접근하거나 이해할 수 없음
- 비용: $10K-$1M+, 기간: 수 주

**지금 (지식 외부화)**:
- 지식이 SKILL.md 파일에 저장됨
- 수정은 그냥 텍스트 편집
- 사람이 읽을 수 있음, 감사 가능
- 비용: 무료, 기간: 즉시

스킬은 **도메인 지식 자체가 명시적 관리가 필요한 리소스**임을 인정합니다.

1. **메타데이터와 콘텐츠 분리**: 설명은 인덱스, 본문은 콘텐츠
2. **필요시 로드**: 컨텍스트 윈도우는 귀중한 인지 자원
3. **표준화된 형식**: 한 번 작성, 호환 가능한 모든 에이전트에서 사용
4. **반환이 아닌 주입**: 스킬은 인지를 바꿈, 데이터만 제공하는 것이 아님
5. **온라인 학습**: 더 큰 컨텍스트 윈도우에서 즉시 학습, 오프라인 학습 불필요

지식 외부화의 본질은 **암묵적 지식을 명시적 문서로 전환**하는 것입니다:
- 개발자가 자연어로 모델에게 새 스킬을 "가르침"
- Git이 지식을 관리하고 공유
- 버전 관리, 감사, 롤백

**이것은 "AI 훈련"에서 "AI 교육"으로의 패러다임 전환입니다.**

## 시리즈 요약

| 버전 | 테마 | 추가된 줄 | 핵심 인사이트 |
|------|------|----------|--------------|
| v1 | 모델이 곧 에이전트 | ~200 | 모델이 80%, 코드는 루프일 뿐 |
| v2 | 구조화된 계획 | ~100 | Todo가 계획을 보이게 함 |
| v3 | 분할 정복 | ~150 | 서브에이전트가 컨텍스트 격리 |
| **v4** | **도메인 전문가** | **~100** | **스킬이 전문성을 주입** |

---

**도구는 모델이 행동하게 합니다. 스킬은 모델이 어떻게 하는지 알게 합니다.**

[← v3](./v3-subagent-mechanism_kr.md) | [README로 돌아가기](../README.md) | [v0 →](./v0-bash-is-all-you-need_kr.md)
